{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries used\n",
    "\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retail data set\n",
    "dataset = pd.read_csv('retail.dat.txt', sep='delimiter', header=None, engine='python')\n",
    "dataset.columns = ['items']\n",
    "df_items = dataset['items']\n",
    "df = df_items.apply(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netflix data set\n",
    "dataset = pd.read_csv('netflix.data', sep='delimiter', header=None, engine='python')\n",
    "dataset.columns = ['items']\n",
    "df_items = dataset['items']\n",
    "df = df_items.apply(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apriori random sampling\n",
    "\n",
    "def apriorirandom(df, min_support=0.01, perc=0.2):\n",
    "    itemsets = {}\n",
    "    # random sampling\n",
    "    df_sampled = df.sample(frac=perc)\n",
    "    transactions = list(map(set, df_sampled))\n",
    "    num_transactions = len(transactions)\n",
    "    min_support_count = min_support * num_transactions\n",
    "\n",
    "    # Making C1\n",
    "    item_counts = {}\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            if item not in item_counts:\n",
    "                item_counts[item] = 0\n",
    "            item_counts[item] += 1\n",
    "\n",
    "    # Loop to keep only the items that meet the support threshold (Making L1)\n",
    "    frequent_itemsets = {}\n",
    "    for item, support in item_counts.items():\n",
    "        if support >= min_support_count:\n",
    "            frequent_itemsets[frozenset([item])] = support\n",
    "    itemsets[1] = frequent_itemsets\n",
    "\n",
    "    # Find the possible candidates(making C2) from the previous l(1)\n",
    "    candidates = set()\n",
    "    for combination in combinations(frequent_itemsets.keys(), 2):\n",
    "        candidates.add(combination)\n",
    "\n",
    "    # Initialize the count to 0 for the amount of pairs\n",
    "    item_counts = {}\n",
    "    for candidate in candidates:\n",
    "        item_counts[candidate] = 0\n",
    "         \n",
    "    # Calculate the frequency of the pairs\n",
    "    for transaction in transactions:\n",
    "        for candidate in candidates:\n",
    "            if set(candidate[0]).issubset(transaction) and set(candidate[1]).issubset(transaction):\n",
    "                item_counts[candidate] += 1\n",
    "\n",
    "    # Making L2\n",
    "    frequent_itemsets = {}\n",
    "    false_positive = defaultdict(int)\n",
    "    for candidate, support in item_counts.items():\n",
    "        if support >= min_support_count:\n",
    "            frequent_itemsets[candidate] = support\n",
    "        else:\n",
    "            false_positive[candidate] += 1\n",
    "                \n",
    "    itemsets[2] = frequent_itemsets\n",
    "    print(\"# of false positives: \", len(false_positive))\n",
    "\n",
    "\n",
    "    return itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCY Random sampling\n",
    "\n",
    "def pcyrandom(df, min_support=0.01, perc=0.2):\n",
    "    itemsets = {}\n",
    "    # random sampling\n",
    "    df_sampled = df.sample(frac=perc)\n",
    "    transactions = list(map(set, df_sampled))\n",
    "    num_transactions = len(transactions)\n",
    "    min_support_count = min_support * num_transactions\n",
    "    \n",
    "    # PCY Pass 1\n",
    "    # Making C1\n",
    "    item_counts = {}\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            if item not in item_counts:\n",
    "                item_counts[item] = 0\n",
    "            item_counts[item] += 1\n",
    "\n",
    "    # Loop to keep only the items that meet the support threshold (Making L1)\n",
    "    frequent_itemsets = {}\n",
    "    for item, support in item_counts.items():\n",
    "        if support >= min_support_count:\n",
    "            frequent_itemsets[frozenset([item])] = support\n",
    "    itemsets[1] = frequent_itemsets\n",
    "            \n",
    "    # Making C2\n",
    "    candidates = set()\n",
    "    for combination in combinations(frequent_itemsets.keys(), 2):\n",
    "        candidates.add(combination)\n",
    "    \n",
    "    buckets = defaultdict(int)\n",
    "    for transaction in transactions:\n",
    "        for candidate in candidates:\n",
    "            if set(candidate[0]).issubset(transaction) and set(candidate[1]).issubset(transaction):\n",
    "                hash_value = (hash(candidate[0]) + hash(candidate[1])) % num_transactions\n",
    "                buckets[hash_value] += 1\n",
    "    \n",
    "    # PCY Pass 2\n",
    "    # Making L2\n",
    "    frequent_pairs = {}\n",
    "    false_positive = defaultdict(int)\n",
    "    for pair, count in buckets.items():\n",
    "        if count >= min_support_count:\n",
    "            frequent_pairs[pair] = count    \n",
    "        else:\n",
    "            false_positive[pair] += 1\n",
    "    itemsets[2] = frequent_pairs\n",
    "    print(\"# of false positives: \", len(false_positive))\n",
    "\n",
    "    return itemsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apriori SON\n",
    "\n",
    "def apriorison(df, min_support=0.01, perc=0.2):\n",
    "    itemsets = {}\n",
    "    transactions = list(map(set, df))\n",
    "    num_transactions = len(transactions)\n",
    "    min_support_count = min_support * num_transactions\n",
    "\n",
    "    # Calculate the number of transactions to use based on percentage\n",
    "    num_transactions_sampled = int(num_transactions * perc)\n",
    "\n",
    "    # Divide transactions into chunks\n",
    "    chunk_size = num_transactions_sampled // 2\n",
    "    chunks = [transactions[i:i+chunk_size] for i in range(0, num_transactions_sampled, chunk_size)]\n",
    "\n",
    "    # First pass to count item frequency in each chunk\n",
    "    chunk_item_counts = [{} for _ in range(len(chunks))]\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        for transaction in chunk:\n",
    "            for item in transaction:\n",
    "                if item not in chunk_item_counts[i]:\n",
    "                    chunk_item_counts[i][item] = 0\n",
    "                chunk_item_counts[i][item] += 1\n",
    "\n",
    "    # Second pass to combine item counts from all chunks\n",
    "    item_counts = {}\n",
    "    for chunk_item_count in chunk_item_counts:\n",
    "        for item, support in chunk_item_count.items():\n",
    "            if item not in item_counts:\n",
    "                item_counts[item] = 0\n",
    "            item_counts[item] += support\n",
    "\n",
    "    # Loop to keep only the items that meet the support threshold (Making L1)\n",
    "    frequent_itemsets = {}\n",
    "    for item, support in item_counts.items():\n",
    "        if support >= min_support_count:\n",
    "            frequent_itemsets[frozenset([item])] = support\n",
    "    itemsets[1] = frequent_itemsets\n",
    "\n",
    "    # Find the possible candidates(making C2) from the previous l(1)\n",
    "    candidates = set()\n",
    "    for combination in combinations(frequent_itemsets.keys(), 2):\n",
    "        candidates.add(combination)\n",
    "\n",
    "    # Initialize the count to 0 for the amount of pairs\n",
    "    item_counts = {}\n",
    "    for candidate in candidates:\n",
    "        item_counts[candidate] = 0\n",
    "         \n",
    "    # Calculate the frequency of the pairs\n",
    "    for chunk in chunks:\n",
    "        for transaction in chunk:\n",
    "            for candidate in candidates:\n",
    "                if set(candidate[0]).issubset(transaction) and set(candidate[1]).issubset(transaction):\n",
    "                    item_counts[candidate] += 1\n",
    "\n",
    "    # Making L2\n",
    "    frequent_itemsets = {}\n",
    "    for candidate, support in item_counts.items():\n",
    "        if support >= min_support_count:\n",
    "            frequent_itemsets[candidate] = support\n",
    "                \n",
    "    itemsets[2] = frequent_itemsets\n",
    "\n",
    "    return itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCY SON\n",
    "\n",
    "def pcyson(df, min_support=0.01, perc=0.2):\n",
    "    itemsets = {}\n",
    "    transactions = list(map(set, df))\n",
    "    num_transactions = len(transactions)\n",
    "    min_support_count = min_support * num_transactions\n",
    "    perc_transactions = int(num_transactions * perc)\n",
    "    \n",
    "    # SON pass 1\n",
    "    # Making C1\n",
    "    item_counts = {}\n",
    "    for transaction in transactions[:perc_transactions]:\n",
    "        for item in transaction:\n",
    "            if item not in item_counts:\n",
    "                item_counts[item] = 0\n",
    "            item_counts[item] += 1\n",
    "\n",
    "    # Loop to keep only the items that meet the support threshold (Making L1)\n",
    "    frequent_itemsets = {}\n",
    "    for item, support in item_counts.items():\n",
    "        if support >= min_support_count:\n",
    "            frequent_itemsets[frozenset([item])] = support\n",
    "    itemsets[1] = frequent_itemsets\n",
    "            \n",
    "    # Making C2\n",
    "    candidates = set()\n",
    "    for combination in combinations(frequent_itemsets.keys(), 2):\n",
    "        candidates.add(combination)\n",
    "    \n",
    "    buckets = defaultdict(int)\n",
    "    for transaction in transactions[:perc_transactions]:\n",
    "        for candidate in candidates:\n",
    "            if set(candidate[0]).issubset(transaction) and set(candidate[1]).issubset(transaction):\n",
    "                hash_value = hash(candidate) % num_transactions\n",
    "                buckets[hash_value] += 1\n",
    "    \n",
    "    # SON pass 2\n",
    "    # Making L2\n",
    "    frequent_pairs = {}\n",
    "    for pair, count in buckets.items():\n",
    "        if count >= min_support_count:\n",
    "            frequent_pairs[pair] = count           \n",
    "    itemsets[2] = frequent_pairs\n",
    "\n",
    "    return itemsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multihash\n",
    "\n",
    "def multihash(df, min_support=0.01, perc=0.2):\n",
    "    itemsets = {}\n",
    "    # random sampling\n",
    "    df_sampled = df.sample(frac=perc)\n",
    "    transactions = list(map(set, df_sampled))\n",
    "    num_transactions = len(transactions)\n",
    "    min_support_count = min_support * num_transactions\n",
    "    \n",
    "    # PCY Pass 1\n",
    "    # Making C1\n",
    "    item_counts = {}\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            if item not in item_counts:\n",
    "                item_counts[item] = 0\n",
    "            item_counts[item] += 1\n",
    "\n",
    "    # Loop to keep only the items that meet the support threshold (Making L1)\n",
    "    frequent_itemsets = {}\n",
    "    for item, support in item_counts.items():\n",
    "        if support >= min_support_count:\n",
    "            frequent_itemsets[frozenset([item])] = support\n",
    "    itemsets[1] = frequent_itemsets\n",
    "            \n",
    "    # Making C2\n",
    "    candidates = set()\n",
    "    for combination in combinations(frequent_itemsets.keys(), 2):\n",
    "        candidates.add(combination)\n",
    "    \n",
    "    # Pass 1 1st hash function\n",
    "    buckets = defaultdict(int)\n",
    "    for transaction in transactions:\n",
    "        for candidate in candidates:\n",
    "            if set(candidate[0]).issubset(transaction) and set(candidate[1]).issubset(transaction):\n",
    "                hash_value = (hash(candidate[0]) + hash(candidate[1])) % num_transactions\n",
    "                buckets[hash_value] += 1\n",
    "                \n",
    "    # Pass 2 2nd hash function\n",
    "    buckets2 = defaultdict(int)\n",
    "    for transaction in transactions:\n",
    "        for candidate in candidates:\n",
    "            if set(candidate[0]).issubset(transaction) and set(candidate[1]).issubset(transaction):\n",
    "                hash_value = (hash(candidate[0]) * hash(candidate[1])) % num_transactions\n",
    "                buckets2[hash_value] += 1\n",
    "    \n",
    "    # Pass 3 check if it is consistent in hash function 1 and 2\n",
    "    # Making L2\n",
    "    frequent_pairs = {}\n",
    "    for pair, count in buckets.items():\n",
    "        if count >= min_support_count and count in buckets2.values():\n",
    "            frequent_pairs[pair] = count           \n",
    "    itemsets[2] = frequent_pairs\n",
    "\n",
    "    return itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing apriori random\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorirandom(df, 0.05, 0.2)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 20% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorirandom(df, 0.05, 0.4)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 40% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorirandom(df, 0.05, 0.6)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 60% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorirandom(df, 0.05, 0.8)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 80% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorirandom(df, 0.05, 1)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 100% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorirandom(df, 0.02, 0.2)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 20% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorirandom(df, 0.02, 0.4)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 40% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorirandom(df, 0.02, 0.6)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 60% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorirandom(df, 0.02, 0.8)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 80% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorirandom(df, 0.02, 1)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 100% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorirandom(df, 0.01, 0.2)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 20% data and 1% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorirandom(df, 0.01, 0.4)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 40% data and 1% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorirandom(df, 0.01, 0.6)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 60% data and 1% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorirandom(df, 0.01, 0.8)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 80% data and 1% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorirandom(df, 0.01, 1)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 100% data and 1% support: \", elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing apriori son\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorison(df, 0.05, 0.2)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 20% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorison(df, 0.05, 0.4)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 40% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorison(df, 0.05, 0.6)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 60% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorison(df, 0.05, 0.8)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 80% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorison(df, 0.05, 1)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 100% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorison(df, 0.02, 0.2)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 20% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorison(df, 0.02, 0.4)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 40% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorison(df, 0.02, 0.6)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 60% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorison(df, 0.02, 0.8)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 80% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorison(df, 0.02, 1)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 100% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorison(df, 0.01, 0.2)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 20% data and 1% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorison(df, 0.01, 0.4)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 40% data and 1% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorison(df, 0.01, 0.6)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 60% data and 1% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorison(df, 0.01, 0.8)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 80% data and 1% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = apriorison(df, 0.01, 1)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run Apriori Algorithm with 100% data and 1% support: \", elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing pcy random\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyrandom(df, 0.05, 0.2)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 20% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyrandom(df, 0.05, 0.4)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 40% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyrandom(df, 0.05, 0.6)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 60% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyrandom(df, 0.05, 0.8)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 80% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyrandom(df, 0.05, 1)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 100% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyrandom(df, 0.02, 0.2)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 20% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyrandom(df, 0.02, 0.4)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 40% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyrandom(df, 0.02, 0.6)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 60% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyrandom(df, 0.02, 0.8)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 80% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyrandom(df, 0.02, 1)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 100% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyrandom(df, 0.01, 0.2)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 20% data and 1% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyrandom(df, 0.01, 0.4)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 40% data and 1% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyrandom(df, 0.01, 0.6)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 60% data and 1% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyrandom(df, 0.01, 0.8)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 80% data and 1% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyrandom(df, 0.01, 1)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 100% data and 1% support: \", elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing pcy son\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyson(df, 0.05, 0.2)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 20% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyson(df, 0.05, 0.4)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 40% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyson(df, 0.05, 0.6)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 60% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyson(df, 0.05, 0.8)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 80% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyson(df, 0.05, 1)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 100% data and 5% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyson(df, 0.02, 0.2)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 20% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyson(df, 0.02, 0.4)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 40% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyson(df, 0.02, 0.6)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 60% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyson(df, 0.02, 0.8)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 80% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyson(df, 0.02, 1)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 100% data and 2% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyson(df, 0.01, 0.2)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 20% data and 1% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyson(df, 0.01, 0.4)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 40% data and 1% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyson(df, 0.01, 0.6)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 60% data and 1% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyson(df, 0.01, 0.8)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 80% data and 1% support: \", elapsed, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "itemsets = pcyson(df, 0.01, 1)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed time to run PCY Algorithm with 100% data and 1% support: \", elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent itemsets for 100% data and 5% support:\n",
      "Itemsets of size 1: 6\n",
      "Itemsets of size 2: 7\n",
      "Frequent itemsets for 100% data and 2% support:\n",
      "Itemsets of size 1: 20\n",
      "Itemsets of size 2: 22\n",
      "Frequent itemsets for 100% data and 1% support:\n",
      "Itemsets of size 1: 70\n",
      "Itemsets of size 2: 57\n",
      "Frequent itemsets for 20% data and 5% support:\n",
      "Itemsets of size 1: 6\n",
      "Itemsets of size 2: 7\n",
      "Frequent itemsets for 20% data and 2% support:\n",
      "Itemsets of size 1: 19\n",
      "Itemsets of size 2: 19\n",
      "Frequent itemsets for 20% data and 1% support:\n",
      "Itemsets of size 1: 72\n",
      "Itemsets of size 2: 36\n"
     ]
    }
   ],
   "source": [
    "# testing multihash\n",
    "itemsets = multihash(df, 0.05, 1)\n",
    "print(\"Frequent itemsets for 100% data and 5% support:\")\n",
    "for k, itemset_counts in itemsets.items():\n",
    "    print(\"Itemsets of size {}: {}\".format(k, len(itemset_counts)))\n",
    "    \n",
    "itemsets = multihash(df, 0.02, 1)\n",
    "print(\"Frequent itemsets for 100% data and 2% support:\")\n",
    "for k, itemset_counts in itemsets.items():\n",
    "    print(\"Itemsets of size {}: {}\".format(k, len(itemset_counts)))\n",
    "    \n",
    "itemsets = multihash(df, 0.01, 1)\n",
    "print(\"Frequent itemsets for 100% data and 1% support:\")\n",
    "for k, itemset_counts in itemsets.items():\n",
    "    print(\"Itemsets of size {}: {}\".format(k, len(itemset_counts)))\n",
    "    \n",
    "itemsets = multihash(df, 0.05, 0.2)\n",
    "print(\"Frequent itemsets for 20% data and 5% support:\")\n",
    "for k, itemset_counts in itemsets.items():\n",
    "    print(\"Itemsets of size {}: {}\".format(k, len(itemset_counts)))\n",
    "    \n",
    "itemsets = multihash(df, 0.02, 0.2)\n",
    "print(\"Frequent itemsets for 20% data and 2% support:\")\n",
    "for k, itemset_counts in itemsets.items():\n",
    "    print(\"Itemsets of size {}: {}\".format(k, len(itemset_counts)))\n",
    "    \n",
    "itemsets = multihash(df, 0.01, 0.2)\n",
    "print(\"Frequent itemsets for 20% data and 1% support:\")\n",
    "for k, itemset_counts in itemsets.items():\n",
    "    print(\"Itemsets of size {}: {}\".format(k, len(itemset_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
